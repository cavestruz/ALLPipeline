{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) average the scores between the _0,_1,_2,_3 directions to get average score per image in each HOG configuration. \n",
    "\n",
    "(2) In each HOG configuration, calculate the Precision and Recall values. \n",
    "\n",
    "(3) \"Bootstrap\" or \"jacknife\" to get an error on the AUC for each HOG configuration, describe how you bootstrapped it in words.\n",
    "\n",
    "(4) Output should look like: \n",
    "\n",
    "HOG config | Precision | Recall | AUC | AUCerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/home/matthew/Data/slacs_strong_lens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datadir):\n",
    "    hognames = [s.split('/')[-1] for s in glob.glob(datadir + '/*')]\n",
    "    return {hogname: [pd.read_csv(filename, sep=None)\n",
    "                      for filename in glob.glob('{}/{}/*'.format(datadir, hogname))]\n",
    "            for hogname in hognames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_scores(dataframes):\n",
    "    dataframes = [df.rename(columns={'score': 'score_{}'.format(idx),\n",
    "                                     'label': 'label_{}'.format(idx)})\n",
    "                  for idx, df in enumerate(dataframes)]\n",
    "    merged_df = reduce(lambda df1, df2: pd.merge(df1, df2, on='filename'))\n",
    "    assert len(set([df.shape[0] for df in dataframes] + [merged_df.shape[0]])) == 1, \\\n",
    "    'Not all keys are the same in the data sets'\n",
    "    \n",
    "    merged_df['score'] = sum(merged_df['score_{}'.format(idx)] for idx, _ in enumerate(dataframes))\n",
    "    merged_df['label'] = merged_df['label_0']\n",
    "    return merged_df[['filename', 'score', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/matthew/Data/slacs_strong_lens/ppc8cpb3/filenames_scores_test3.txt',\n",
       " '/home/matthew/Data/slacs_strong_lens/ppc8cpb3/filenames_scores_test1.txt',\n",
       " '/home/matthew/Data/slacs_strong_lens/ppc8cpb3/filenames_scores_test0.txt',\n",
       " '/home/matthew/Data/slacs_strong_lens/ppc8cpb3/filenames_scores_test2.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(datadir + '/ppc8cpb3/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/Source/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/matthew/Data/slacs_strong_lens/ppc8cpb3/filenames_scores_test3.txt', sep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename     object\n",
       "score       float64\n",
       "label         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/avestruz/StrongCNN/control_set/10000/out...</td>\n",
       "      <td>0.094018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/avestruz/StrongCNN/control_set/10000/out...</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/avestruz/StrongCNN/control_set/10000/out...</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/avestruz/StrongCNN/control_set/10000/out...</td>\n",
       "      <td>0.215122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/avestruz/StrongCNN/control_set/10000/out...</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename     score  label\n",
       "0  /data/avestruz/StrongCNN/control_set/10000/out...  0.094018      0\n",
       "1  /data/avestruz/StrongCNN/control_set/10000/out...  0.003774      0\n",
       "2  /data/avestruz/StrongCNN/control_set/10000/out...  0.002381      0\n",
       "3  /data/avestruz/StrongCNN/control_set/10000/out...  0.215122      0\n",
       "4  /data/avestruz/StrongCNN/control_set/10000/out...  0.943013      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
